{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: <class 'numpy.uint8'>\n",
      "y: <class 'numpy.uint8'>\n",
      "(39209, 900) (39209, 1)\n"
     ]
    }
   ],
   "source": [
    "#this works as long as it is inside code/\n",
    "train_path = os.getcwd()[:-4] + \"archive/train/\"\n",
    "test_path = os.getcwd()[:-4] + \"archive/test/\"\n",
    "\n",
    "classes = os.listdir(train_path)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_ in classes:\n",
    "    full_path = train_path + str(class_) + \"/\"\n",
    "    for file in os.listdir(full_path):\n",
    "        img = Image.open(full_path + file)\n",
    "\n",
    "        #needs to resize\n",
    "        img = img.resize((30, 30))\n",
    "\n",
    "        #Convert image to grayscale\n",
    "        img = img.convert('L')\n",
    "        \n",
    "        #Convert image to numpy array (Feature Extraction)\n",
    "        img = np.array(img).flatten()\n",
    "        img.reshape(img.shape[0], 1)\n",
    "\n",
    "        #Append image to list\n",
    "        images.append(img)\n",
    "\n",
    "        #Append label to list\n",
    "        labels.append(np.uint8(class_))\n",
    "        \n",
    "\n",
    "\n",
    "X = np.array(images)\n",
    "print(\"X:\", type(X[0][0]))\n",
    "y = np.array(labels)\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "print(\"y:\", type(y[0][0]))\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data without sklearn\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    if test_size >= 1 or test_size <= 0:\n",
    "        raise ValueError(\"test_size must be smaller than 1 and larger than 0\")\n",
    "    \n",
    "    \n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    test_set_size = int(len(X) * test_size)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return np.array(X[train_indices]), np.array(X[test_indices]), np.array(y[train_indices]), np.array(y[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for file in os.listdir(test_path):\n",
    "    #Ignore csv file\n",
    "    if file.endswith(\".csv\"):\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(test_path + file)\n",
    "\n",
    "    #needs to resize\n",
    "    img = img.resize((30, 30))\n",
    "\n",
    "    #Convert image to grayscale\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    #Convert image to numpy array (Feature Extraction)\n",
    "    img = np.array(img).flatten()\n",
    "    img.reshape(img.shape[0], 1)\n",
    "\n",
    "    #Append image to list\n",
    "    test_images.append(img)\n",
    "\n",
    "    #Append label to list\n",
    "    test_labels.append(np.uint8(class_))\n",
    "\n",
    "X_original_test, y_original_test = np.array(test_images), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "def featureNormalization(X):\n",
    "    \"\"\"\n",
    "    Take in numpy array of X values and return normalize X values,\n",
    "    the mean and standard deviation of each feature\n",
    "    \"\"\"\n",
    "    mean= np.mean(X, axis=0)\n",
    "    std= np.std(X, axis=0)\n",
    "    \n",
    "    X_norm = (X - mean) / std\n",
    "    \n",
    "    return X_norm , mean , std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X_train and X_test (feature scaling)\n",
    "X_train, mean, std = featureNormalization(X_train)\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogo/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/diogo/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000)\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy: 0.9897666411629686\n"
     ]
    }
   ],
   "source": [
    "#Predict using train set\n",
    "pred = lg.predict(X_train)\n",
    "scores = lg.score(X_train, y_train)\n",
    "print(\"Train set Accuracy:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy: 0.9201632444841219\n"
     ]
    }
   ],
   "source": [
    "#Predict using test set\n",
    "pred=lg.predict(X_test)\n",
    "scores = lg.score(X_test, y_test)\n",
    "print(\"Test set Accuracy:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy: 0.035629453681710214\n"
     ]
    }
   ],
   "source": [
    "#Predict using original test set\n",
    "pred=lg.predict(X_original_test)\n",
    "scores = lg.score(X_original_test, y_original_test)\n",
    "print(\"Test set Accuracy:\", scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
